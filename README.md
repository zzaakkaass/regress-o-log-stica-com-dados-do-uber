ğŸ” Comparativo de Algoritmos de Machine Learning - PrevisÃ£o de Corridas Uber
ğŸ¯ Objetivo
Comparar o desempenho de trÃªs algoritmos de classificaÃ§Ã£o diferentes na previsÃ£o de corridas completadas da Uber, analisando suas caracterÃ­sticas e aplicabilidades.

ğŸ“Š Sobre o Projeto
Este projeto realiza uma anÃ¡lise comparativa entre RegressÃ£o LogÃ­stica, K-Nearest Neighbors (KNN) e Ãrvores de DecisÃ£o para entender qual algoritmo se adapta melhor aos padrÃµes dos dados da Uber, considerando diferentes cenÃ¡rios e complexidades dos dados.

ğŸ§  Algoritmos Comparados
1. RegressÃ£o LogÃ­stica
```
LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)
Melhor para: RelaÃ§Ãµes predominantemente lineares
```
Vantagens: Interpretabilidade, probabilidades bem calibradas

LimitaÃ§Ãµes: Assume linearidade entre features e log-odds

2. K-Nearest Neighbors (KNN)
```
KNeighborsClassifier(n_neighbors=5, weights='uniform')
Melhor para: PadrÃµes locais complexos
```
Vantagens: NÃ£o assume forma funcional especÃ­fica, simples

LimitaÃ§Ãµes: Computacionalmente intensivo, sensÃ­vel a escala

3. Ãrvore de DecisÃ£o
```
DecisionTreeClassifier(max_depth=5, random_state=42)
```
Melhor para: Capturar regras especÃ­ficas e nÃ£o-lineares

Vantagens: InterpretÃ¡vel, lida bem com features categÃ³ricas

LimitaÃ§Ãµes: TendÃªncia a overfitting, instÃ¡vel

ğŸ“ˆ Features Utilizadas
Avg VTAT - Vehicle Turnaround Average Time

Avg CTAT - Customer Turnaround Average Time

ğŸ› ï¸ ImplementaÃ§Ã£o
Pipeline de Machine Learning
```
# Pipeline padrÃ£o para todos os algoritmos
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', algoritmo_escolhido)
])
```
MÃ©tricas de AvaliaÃ§Ã£o
python
```
# MÃ©tricas calculadas para cada algoritmo
metrics = {
    'Accuracy': accuracy_score,
    'Precision': precision_score,
    'Recall': recall_score,
    'F1-Score': f1_score,
    'ROC AUC': roc_auc_score
}
```
ğŸ“Š Resultados e AnÃ¡lise
Fronteira de DecisÃ£o
A visualizaÃ§Ã£o da fronteira de decisÃ£o permite comparar como cada algoritmo separa as classes:

```
# VisualizaÃ§Ã£o da fronteira de decisÃ£o
plt.contourf(xx, yy, zz, levels=25, cmap='RdBu', alpha=0.6)
plt.contour(xx, yy, zz, levels=[0.5], colors=['k'], linewidths=2)
```
InterpretaÃ§Ã£o das fronteiras:

Linha preta (0.5): Limite de decisÃ£o (50% probabilidade)

RegiÃ£o azul: Probabilidade baixa de "completado"

RegiÃ£o vermelha: Probabilidade alta de "completado"

ğŸ¯ CenÃ¡rios de AplicaÃ§Ã£o
âœ… RegressÃ£o LogÃ­stica
Dados com relaÃ§Ãµes lineares claras

Quando interpretabilidade Ã© crucial

Dataset com muitas features

âœ… KNN
PadrÃµes locais complexos

Datasets pequenos a mÃ©dios

Quando a mÃ©trica de distÃ¢ncia faz sentido

âœ… Ãrvore de DecisÃ£o
Regras de negÃ³cio especÃ­ficas

Features categÃ³ricas

Quando precisa de alta interpretabilidade

ğŸ“‹ Estrutura do Projeto
text
comparativo_algoritmos/
â”‚
â”œâ”€â”€ dados_uber.csv
â”œâ”€â”€ comparativo_regressao_logistica.py
â”œâ”€â”€ comparativo_knn.py
â”œâ”€â”€ comparativo_arvore_decisao.py
â”œâ”€â”€ analise_comparativa_final.py
â””â”€â”€ README.md
ğŸ”§ Como Executar
bash
# Instalar dependÃªncias
pip install pandas numpy matplotlib scikit-learn

# Executar anÃ¡lise comparativa
python analise_comparativa_final.py
ğŸ“Š MÃ©tricas de ComparaÃ§Ã£o
Algoritmo	Accuracy	Precision	Recall	F1-Score	ROC AUC
RegressÃ£o LogÃ­stica					
KNN					
Ãrvore de DecisÃ£o					
ğŸ“ ConclusÃµes Aprendidas
NÃ£o existe algoritmo universalmente melhor

A escolha depende da natureza dos dados

A visualizaÃ§Ã£o ajuda a entender o comportamento dos modelos

O balanceamento entre bias e variaÃ§Ã£o Ã© crucial

ğŸš€ PrÃ³ximos Passos
Implementar Ensemble Methods (Random Forest, Gradient Boosting)

Adicionar mais features ao modelo

Realizar tuning de hiperparÃ¢metros

Implementar cross-validation

Desenvolver dashboard interativo
